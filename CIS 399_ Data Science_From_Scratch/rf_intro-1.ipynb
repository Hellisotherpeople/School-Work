{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".h1_cell, .just_text {\n",
       "    box-sizing: border-box;\n",
       "    padding-top:5px;\n",
       "    padding-bottom:5px;\n",
       "    font-family: \"Times New Roman\", Georgia, Serif;\n",
       "    font-size: 125%;\n",
       "    line-height: 22px; /* 5px +12px + 5px */\n",
       "    text-indent: 25px;\n",
       "    background-color: #fbfbea;\n",
       "    padding: 10px;\n",
       "}\n",
       "\n",
       "hr { \n",
       "    display: block;\n",
       "    margin-top: 0.5em;\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "    border-style: inset;\n",
       "    border-width: 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".h1_cell, .just_text {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-family: \"Times New Roman\", Georgia, Serif;\n",
    "    font-size: 125%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    text-indent: 25px;\n",
    "    background-color: #fbfbea;\n",
    "    padding: 10px;\n",
    "}\n",
    "\n",
    "hr { \n",
    "    display: block;\n",
    "    margin-top: 0.5em;\n",
    "    margin-bottom: 0.5em;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    border-style: inset;\n",
    "    border-width: 2px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 6: Random Forests - another approach to Bias-Variance\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "In this module we will continue to look at means of tackling the Bias-Variance problem. We will focus on the Variance problem of overfitting. We will see a new concept called *ensemble* learning. I liken it to crowd-sourcing. Instead of relying on just one expert, let's round up a collection (AKA an ensemble) of experts. We can let them each, individually, come up with a prediction. Then we can take a vote and use the winning prediction.\n",
    "<p>\n",
    "The technique we will look at is called *Random Forests*. It is a special method falling under the more general heading of *bagging*. We will crowd-source a forest of trees to get their predictions and then take majority vote. Where, you ask, does this forest of trees come from? We build them following relatively straightforward steps. So to summarize, we first build our forest of decision trees. Then when we want to do predictions for real, we give each tree a vote and majority wins. Cool.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Jargon alerts\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Random forests have jargon that goes with them. I'll alert you to where jargony terms show up.\n",
    "<p>\n",
    "Jargon alert: *Random Forest* is jargon :) And so is *bagging* and *ensemble*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "week = 5  # from last module\n",
    "\n",
    "home_path =  os.path.expanduser('~')\n",
    "\n",
    "file_path = '/Dropbox/cis399_ds1_f17/notebook_history/'\n",
    "\n",
    "file_name = 'titanic_wrangled_w'+str(week)+'.csv'\n",
    "\n",
    "titanic_table = pd.read_csv(home_path + file_path + file_name)\n",
    "\n",
    "pd.__version__  # should see 0.20.3 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home_path + '/Dropbox/cis399_ds1_f17/week_libraries/datascience_1')\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(home_path + '/Dropbox/cis399_ds1_f17/week_libraries/datascience_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t build_pred\t build_tree_iter\t caser\t compute_prediction\t compute_training\t f1\t find_best_splitter\t generate_table\t \n",
      "gig\t gini\t informedness\t k_fold\t predictor_case\t probabilities\t tree_predictor\t \n"
     ]
    }
   ],
   "source": [
    "from week5 import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                     Name   Sex   Age  SibSp  Parch  \\\n",
       "0         0       3  Braund, Mr. Owen Harris  male  22.0      1      0   \n",
       "\n",
       "      Ticket  Fare Cabin Embarked  no_age  filled_age  emb_C  emb_Q  emb_S  \\\n",
       "0  A/5 21171  7.25   NaN        S       0        22.0      0      0      1   \n",
       "\n",
       "   emb_nan age_bin  age_Child  age_Adult  age_Senior  sex_female  sex_male  \\\n",
       "0        0   Child          1          0           0           0         1   \n",
       "\n",
       "   ok_child  pclass_1  pclass_2  pclass_3  pclass_nan  \n",
       "0         0         0         0         1           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "A forest starts with some trees\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Let's build a forest of two trees to get started. Once we see how to do that, we can scale it up to N trees.\n",
    "<p>\n",
    "Our approach will be to do random selections of both the rows (axis=0) and columns (axis=1) as we build the tree.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Step 1. Generate the training data for the first tree (and don't lose the left-out data)\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We will take a slice from the entire table to use as training. This may sound familiar: we did something similar when doing K-folding. The big difference here is that we will take random rows *with replacement*. This means the same row can appear more than once in our slice. With K-Folding, we did not let this happen. And BTW, the size of the slice is the size of the original table, e.g. 891 rows in slice!\n",
    "<p>\n",
    "We don't want to lose track of the rows we did not use. They will become important later.\n",
    "<p>\n",
    "Jargon alert: selecting a random sample of rows for training (with replacement) is called *bootstrapping* or *bagging*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Random but predictable\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I am going to be needing random values both in Python and in Pandas. I am going to set things up so that I always get the same random values when I restart the kernel and run this notebook from the top. Why? Helps me debug to have the same values every time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All this does is give me a function that produces a sequence of ints starting at the seed.\n",
    "# I'm using a closure to hide the counter z. Could use a Python class but here I like a closure better.\n",
    "\n",
    "def seeder(seed):\n",
    "    z = [seed]  # why embed in list? See https://stackoverflow.com/a/4851555\n",
    "    def f():\n",
    "        val = z[0]\n",
    "        z[0] += 1\n",
    "        return val\n",
    "    return f\n",
    "\n",
    "new_seed = seeder(100)  # new_seed is a function that will return a sequence of ints, one on each new call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1000)  # this seeds the Python random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Let's bootstrap!\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We need a table that is same size as Titanic table (891 rows). We will select the rows in the Titanic Table randomly. We will allow replacement: the same row can be selected mulitple times. What is very cool is that Pandas gives us a method, `sample`, that does exactly what we want. Pretty nice of them.\n",
    "<p>\n",
    "As you can see below, I am setting the fraction of the table I want to 100%. And I am using my new_seed function to give me the random seed.\n",
    "<p>\n",
    "Once I have my new table, I am going to reindex it. This will create a new column `index` that has the row numbers from the original Titanic table. I'll want those later. Check it out.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Perreault, Miss. Anne</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12749</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>B73</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Compton, Miss. Sara Rebecca</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17756</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>E49</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Aks, Mrs. Sam (Leah Rosen)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392091</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Survived  Pclass                                              Name  \\\n",
       "0    520         1       1                             Perreault, Miss. Anne   \n",
       "1    792         0       3                           Sage, Miss. Stella Anna   \n",
       "2    835         1       1                       Compton, Miss. Sara Rebecca   \n",
       "3    871         1       1  Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
       "4    855         1       3                        Aks, Mrs. Sam (Leah Rosen)   \n",
       "\n",
       "      Sex   Age  SibSp  Parch    Ticket     Fare Cabin Embarked  no_age  \\\n",
       "0  female  30.0      0      0     12749  93.5000   B73        S       0   \n",
       "1  female   NaN      8      2  CA. 2343  69.5500   NaN        S       1   \n",
       "2  female  39.0      1      1  PC 17756  83.1583   E49        C       0   \n",
       "3  female  47.0      1      1     11751  52.5542   D35        S       0   \n",
       "4  female  18.0      0      1    392091   9.3500   NaN        S       0   \n",
       "\n",
       "   filled_age  emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  age_Adult  \\\n",
       "0   30.000000      0      0      1        0   Adult          0          1   \n",
       "1   29.699118      0      0      1        0   Adult          0          1   \n",
       "2   39.000000      1      0      0        0   Adult          0          1   \n",
       "3   47.000000      0      0      1        0   Adult          0          1   \n",
       "4   18.000000      0      0      1        0   Child          1          0   \n",
       "\n",
       "   age_Senior  sex_female  sex_male  ok_child  pclass_1  pclass_2  pclass_3  \\\n",
       "0           0           1         0         0         1         0         0   \n",
       "1           0           1         0         0         0         0         1   \n",
       "2           0           1         0         0         1         0         0   \n",
       "3           0           1         0         0         1         0         0   \n",
       "4           0           1         0         0         0         0         1   \n",
       "\n",
       "   pclass_nan  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = titanic_table.sample(frac=1.0, replace=True, random_state=new_seed())  # Easy peasy - thanks pandas!\n",
    "train1 = train1.reset_index()\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     595\n",
       "False    296\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for giggles, get a count of how many rows duplicated in train1\n",
    "train1.duplicated(['index'], keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "We will need the leftovers eventually\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Since we have duplicates in `train1`, there must be some rows from the Titanic table that were not included in train1. I would like to know which rows were left out of train1.\n",
    "<p>\n",
    "Jargon alert: the rows that are left out are called *out of bag*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Survived  Pclass                             Name     Sex   Age  \\\n",
       "0     10         1       3  Sandstrom, Miss. Marguerite Rut  female   4.0   \n",
       "1     12         0       3   Saundercock, Mr. William Henry    male  20.0   \n",
       "2     19         1       3          Masselmani, Mrs. Fatima  female   NaN   \n",
       "3     22         1       3      McGowan, Miss. Anna \"Annie\"  female  15.0   \n",
       "4     23         1       1     Sloper, Mr. William Thompson    male  28.0   \n",
       "\n",
       "   SibSp  Parch     Ticket     Fare Cabin Embarked  no_age  filled_age  emb_C  \\\n",
       "0      1      1    PP 9549  16.7000    G6        S       0    4.000000      0   \n",
       "1      0      0  A/5. 2151   8.0500   NaN        S       0   20.000000      0   \n",
       "2      0      0       2649   7.2250   NaN        C       1   29.699118      1   \n",
       "3      0      0     330923   8.0292   NaN        Q       0   15.000000      0   \n",
       "4      0      0     113788  35.5000    A6        S       0   28.000000      0   \n",
       "\n",
       "   emb_Q  emb_S  emb_nan age_bin  age_Child  age_Adult  age_Senior  \\\n",
       "0      0      1        0   Child          1          0           0   \n",
       "1      0      1        0   Child          1          0           0   \n",
       "2      0      0        0   Adult          0          1           0   \n",
       "3      1      0        0   Child          1          0           0   \n",
       "4      0      1        0   Adult          0          1           0   \n",
       "\n",
       "   sex_female  sex_male  ok_child  pclass_1  pclass_2  pclass_3  pclass_nan  \n",
       "0           1         0         1         0         0         1           0  \n",
       "1           0         1         0         0         0         1           0  \n",
       "2           1         0         0         0         0         1           0  \n",
       "3           1         0         0         0         0         1           0  \n",
       "4           0         1         0         1         0         0           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out1 = titanic_table.loc[~titanic_table.index.isin(train1['index'])]\n",
    "left_out1 = left_out1.reset_index()  #builds a new index column\n",
    "left_out1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We expect no True values with this - should have unique rows\n",
    "left_out1.duplicated(['index'], keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We don't really need the entire left_out1 table. All we need are the values in the `index` column. We can use those to access rows in the Titanic table later. So will pull those indices out and put in a list.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 12, 19, 22, 23]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_indices1 = left_out1['index'].tolist()\n",
    "left_out_indices1[:5]  # should be same as what see in head() above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Let's congratulate ourselves\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We have completed the first big step in building our two-tree forest. We have generated a bootstrapped table, `train1`, that we can use for training our first tree.\n",
    "<p>\n",
    "Next step is to do the training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter_columns = [\n",
    " 'emb_C',\n",
    " 'emb_Q',\n",
    " 'emb_S',\n",
    " 'emb_nan',\n",
    " 'age_Child',\n",
    " 'age_Adult',\n",
    " 'age_Senior',\n",
    " 'no_age',\n",
    " 'ok_child',\n",
    " 'sex_female',\n",
    " 'pclass_1',\n",
    " 'pclass_2',\n",
    " 'pclass_3',\n",
    " 'pclass_nan'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Training is a bit different\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Normally we would use all the columns in splitter_columns to build our tree. We are going to do something different. For each node in the tree we are building, I will only choose the best splitter from a subset of splitter_columns. What I choose to be in the subset will be random. The size of the subset, which I will call `m`, is a hyper-parameter that you can set. A rule of thumb is to set `m` to (at max) the square root of the length of `splitter_columns`. That length is 14 so I will use a value of 3 for m.\n",
    "<p>\n",
    "Jargon alert: choosing a random subset of columns/features is called *attribute bagging* which is a type of *random subspace sampling*.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(len(splitter_columns)**.5)  # default is square root of total number of splitters rounded down\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "The Fickas variation\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Normally we would take a sample of m *with* replacement. That means, for m = 3, we could potentially have the result be `['no_age', 'no_age', 'no_age']`. Thought question: how would this shake out with `find_best_splitter`?\n",
    "<p>\n",
    "For efficiency, I am going to sample *without* replacement. So I am not allowing duplicates in my resulting list. I'll pay a price for this potentially. What is that price? Work on my thought question :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass_1', 'ok_child', 'emb_Q']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use random library sample method to get sample without replacement\n",
    "rcols = random.sample(splitter_columns, m)\n",
    "rcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We now have the candidate splitters (3 of them) for the root node of tree. We can use our library functions from past modules to do the rest.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pclass_1', 0.033921730457458055)\n"
     ]
    }
   ],
   "source": [
    "columns_sorted = find_best_splitter(train1, rcols, 'Survived')  #notice using train1 and rcols\n",
    "(best_column, gig_value) = columns_sorted[0]\n",
    "print((best_column, gig_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now we can build the 2 starting paths emanating from the root node.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_1_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.033921730457458055,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_1_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.033921730457458055,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value},\n",
    "                 {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value}]\n",
    "                 \n",
    "current_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "I'll follow another round of splitting, i.e., grow the tree to level 2. I am copying and pasting code from `build_tree_iter` here. But I am making some changes, which I'll mark with `new` comments.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = train1\n",
    "\n",
    "tree_paths = []\n",
    "new_paths = []\n",
    "gig_cutoff = 0.0\n",
    "\n",
    "for path in current_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    rcols = random.sample(splitter_columns, m)       #new - chooses random subset for each node\n",
    "    columns_sorted = find_best_splitter(before_table, rcols, 'Survived')  #new - using rcols\n",
    "    (best_column, gig_value) = columns_sorted[0]\n",
    "    if gig_value > gig_cutoff:\n",
    "        new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value}\n",
    "        new_paths.append( new_path_1 ) #true\n",
    "        new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value\n",
    "                     }\n",
    "        new_paths.append( new_path_0 ) #false\n",
    "    else:\n",
    "        #not worth splitting so complete the path with a prediction\n",
    "        path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "        tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_1_1', <function week4.<lambda>>),\n",
       "   ('age_Child_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.01159708069026677,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_1_1', <function week4.<lambda>>),\n",
       "   ('age_Child_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.01159708069026677,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_1_0', <function week4.<lambda>>),\n",
       "   ('ok_child_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.018515700385069722,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_1_0', <function week4.<lambda>>),\n",
       "   ('ok_child_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.018515700385069722,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths  # should be empty list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "I'll stop here with a tree of level 2. Now copy path info into tree_paths so includes predictions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in new_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "    tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_1_1', <function week4.<lambda>>),\n",
       "   ('age_Child_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.01159708069026677,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('pclass_1_1', <function week4.<lambda>>),\n",
       "   ('age_Child_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.01159708069026677,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('pclass_1_0', <function week4.<lambda>>),\n",
       "   ('ok_child_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.018515700385069722,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('pclass_1_0', <function week4.<lambda>>),\n",
       "   ('ok_child_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.018515700385069722,\n",
       "  'prediction': 0}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "I'm going to add another attribute `oob` to a tree. It stands for Out of Bag. We will make use of it later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree1 = {'paths': tree_paths, 'weight': None, 'oob': left_out_indices1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = [tree1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Big hand clap\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We have successfully built the first tree in the forest. We could stop here with a one-tree forest (boring). Let's add at least one more tree.\n",
    "<p>\n",
    "I'll build the second tree without much in way of comments. It will look the same as construction of tree1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First generate new training data - every tree gets its own data\n",
    "train2 = titanic_table.sample(frac=1.0, replace=True, random_state=new_seed())\n",
    "left_out2 = titanic_table.loc[~titanic_table.index.isin(train2.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.reset_index()\n",
    "left_out2 =left_out2.reset_index()\n",
    "left_out_indices2 = left_out2['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     565\n",
       "False    326\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.duplicated(['index'], keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 7, 8]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_indices2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_Adult', 'age_Senior', 'emb_S']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the root node\n",
    "\n",
    "rcols = random.sample(splitter_columns, m)\n",
    "rcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emb_S', 0.03150290796366739)\n"
     ]
    }
   ],
   "source": [
    "columns_sorted = find_best_splitter(train2, rcols, 'Survived')\n",
    "(best_column, gig_value) = columns_sorted[0]\n",
    "print((best_column, gig_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('emb_S_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.03150290796366739,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('emb_S_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.03150290796366739,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value},\n",
    "                 {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value}]\n",
    "                 \n",
    "current_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = train2\n",
    "\n",
    "tree_paths = []\n",
    "new_paths = []\n",
    "gig_cutoff = 0.0\n",
    "\n",
    "for path in current_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    rcols = random.sample(splitter_columns, m)       #new - chooses random subset for each node\n",
    "    columns_sorted = find_best_splitter(before_table, rcols, 'Survived')  #using rcols\n",
    "    (best_column, gig_value) = columns_sorted[0]\n",
    "    if gig_value > gig_cutoff:\n",
    "        new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value}\n",
    "        new_paths.append( new_path_1 ) #true\n",
    "        new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value\n",
    "                     }\n",
    "        new_paths.append( new_path_0 ) #false\n",
    "    else:\n",
    "        #not worth splitting so complete the path with a prediction\n",
    "        path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "        tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('emb_S_1', <function week4.<lambda>>),\n",
       "   ('sex_female_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.09709945586203417,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('emb_S_1', <function week4.<lambda>>),\n",
       "   ('sex_female_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.09709945586203417,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('emb_S_0', <function week4.<lambda>>),\n",
       "   ('pclass_3_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.07297366447176823,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('emb_S_0', <function week4.<lambda>>),\n",
       "   ('pclass_3_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.07297366447176823,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in new_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "    tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('emb_S_1', <function week4.<lambda>>),\n",
       "   ('sex_female_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.09709945586203417,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('emb_S_1', <function week4.<lambda>>),\n",
       "   ('sex_female_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.09709945586203417,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('emb_S_0', <function week4.<lambda>>),\n",
       "   ('pclass_3_1', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.07297366447176823,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('emb_S_0', <function week4.<lambda>>),\n",
       "   ('pclass_3_0', <function week4.<lambda>>)],\n",
       "  'gig_score': 0.07297366447176823,\n",
       "  'prediction': 1}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree2 = {'paths': tree_paths, 'weight': None, 'oob': left_out_indices2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1.append(tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Let's stop at a two-tree forest\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "It would be better to have an odd number to break voting ties, but we will figure something out.\n",
    "<p>\n",
    "Now that we have a forest, let's see how to use it for prediction. I'll define a new function, `vote_taker`, that tallies up the votes of all the trees for a single row. Ties go to the negative outcome 0 (arbitrarily).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vote_taker(row, forest):\n",
    "    votes = {0:0, 1:0}\n",
    "    for tree in forest:\n",
    "        prediction = tree_predictor(row, tree)\n",
    "        votes[prediction] += 1\n",
    "    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row0 = titanic_table.loc[0]\n",
    "vote_taker(row0, forest1)  #tree1 0, tree2 0, winner 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'm going to go back to using the Titanic table to keep our predictions for now. Not quite ready to set up a full-blown results table.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, use forest on entire table\n",
    "\n",
    "titanic_table['forest_1'] = titanic_table.apply(lambda row: vote_taker(row, forest1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "      <th>forest_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   no_age  filled_age  emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  \\\n",
       "0       0        22.0      0      0      1        0   Child          1   \n",
       "1       0        38.0      1      0      0        0   Adult          0   \n",
       "2       0        26.0      0      0      1        0   Child          1   \n",
       "3       0        35.0      0      0      1        0   Adult          0   \n",
       "4       0        35.0      0      0      1        0   Adult          0   \n",
       "\n",
       "   age_Adult  age_Senior  sex_female  sex_male  ok_child  pclass_1  pclass_2  \\\n",
       "0          0           0           0         1         0         0         0   \n",
       "1          1           0           1         0         0         1         0   \n",
       "2          0           0           1         0         0         0         0   \n",
       "3          1           0           1         0         0         1         0   \n",
       "4          1           0           0         1         0         0         0   \n",
       "\n",
       "   pclass_3  pclass_nan  forest_1  \n",
       "0         1           0         0  \n",
       "1         0           0         1  \n",
       "2         1           0         0  \n",
       "3         0           0         1  \n",
       "4         1           0         0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_table['forest_1_type'] = titanic_table.apply(lambda row: predictor_case(row, pred='forest_1', target='Survived'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "      <th>forest_1</th>\n",
       "      <th>forest_1_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>true_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>false_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>true_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   no_age  filled_age  emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  \\\n",
       "0       0        22.0      0      0      1        0   Child          1   \n",
       "1       0        38.0      1      0      0        0   Adult          0   \n",
       "2       0        26.0      0      0      1        0   Child          1   \n",
       "3       0        35.0      0      0      1        0   Adult          0   \n",
       "4       0        35.0      0      0      1        0   Adult          0   \n",
       "\n",
       "   age_Adult  age_Senior  sex_female  sex_male  ok_child  pclass_1  pclass_2  \\\n",
       "0          0           0           0         1         0         0         0   \n",
       "1          1           0           1         0         0         1         0   \n",
       "2          0           0           1         0         0         0         0   \n",
       "3          1           0           1         0         0         1         0   \n",
       "4          1           0           0         1         0         0         0   \n",
       "\n",
       "   pclass_3  pclass_nan  forest_1   forest_1_type  \n",
       "0         1           0         0   true_negative  \n",
       "1         0           0         1   true_positive  \n",
       "2         1           0         0  false_negative  \n",
       "3         0           0         1   true_positive  \n",
       "4         1           0         0   true_negative  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_negative     514\n",
       "false_negative    219\n",
       "true_positive     123\n",
       "false_positive     35\n",
       "Name: forest_1_type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1_types = titanic_table['forest_1_type'].value_counts()  # returns a series\n",
    "forest1_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7149270482603816, 0.49200000000000005, 0.29589684593998644)\n"
     ]
    }
   ],
   "source": [
    "print((accuracy(forest1_types), f1(forest1_types), informedness(forest1_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Not that good\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'd like to try larger forests. Maybe 10 trees in the forest. But to do that, I don't want to copy and paste all that code. What I would like is a function that can build a forest for me, taking as a hyper parameter how many trees to include. Here is the start.\n",
    "<pre>\n",
    "<code>\n",
    "def forest_builder(table, column_choices, target, hypers):\n",
    "    depth = 2 if 'max-depth' not in hypers else hypers['max-depth']\n",
    "    tree_n = 5 if 'total-trees' not in hypers else hypers['total-trees']\n",
    "    m = int(len(column_choices)**.5) if 'm' not in hypers else hypers['m']\n",
    "</code>\n",
    "</pre>\n",
    "<p>\n",
    "The return should be a forest, i.e., a list of trees as seen above.\n",
    "<p>\n",
    "My implementation borrows heavily from `tree_builder_iter` from module 4. I am still using the nested function `iterative_build` to build a tree. But I have modified it to use bootstrapped training data for each tree and a random subset of attributes for each node in a tree. At the bottom I repeatedly call `iterative_build` to generate the trees for my forest.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_builder(table, column_choices, target, hypers):\n",
    "    tree_n = 5 if 'total-trees' not in hypers else hypers['total-trees']\n",
    "    m = int(len(column_choices)**.5) if 'm' not in hypers else hypers['m']\n",
    "    k = hypers['max-depth'] if 'max-depth' in hypers else min(2, len(column_choices))\n",
    "    gig_cutoff = hypers['gig-cutoff'] if 'gig-cutoff' in hypers else 0.0\n",
    "\n",
    "    #build a single tree - call it multiple times to build multiple trees\n",
    "    def iterative_build(k):\n",
    "        train = table.sample(frac=1.0, replace=True, random_state=new_seed())\n",
    "        train = train.reset_index()\n",
    "        left_out = table.loc[~table.index.isin(train['index'])]\n",
    "        left_out = left_out.reset_index() # this gives us the old index in its own column\n",
    "        oob_list = left_out['index'].tolist()  # list of row indices from original titanic table\n",
    "        \n",
    "        rcols = random.sample(column_choices, m)  # subspcace sampling\n",
    "        columns_sorted = find_best_splitter(train, rcols, target)\n",
    "        (best_column, gig_value) = columns_sorted[0]\n",
    "\n",
    "        #Note I add _1 or _0 to make it more readable for debugging\n",
    "        current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value},\n",
    "                         {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value}\n",
    "                        ]\n",
    "        k -= 1  # we just built a level as seed so subtract 1 from k\n",
    "        tree_paths = []  # add completed paths here\n",
    "\n",
    "        while k>0:\n",
    "            new_paths = []\n",
    "            for path in current_paths:\n",
    "                conjunct = path['conjunction']  # a list of (name, lambda)\n",
    "                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\n",
    "                rcols = random.sample(column_choices, m)  # subspace\n",
    "                columns_sorted = find_best_splitter(before_table, rcols, target)\n",
    "                (best_column, gig_value) = columns_sorted[0]\n",
    "                if gig_value > gig_cutoff:\n",
    "                    new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value}\n",
    "                    new_paths.append( new_path_1 ) #true\n",
    "                    new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value\n",
    "                                 }\n",
    "                    new_paths.append( new_path_0 ) #false\n",
    "                else:\n",
    "                    #not worth splitting so complete the path with a prediction\n",
    "                    path['prediction'] = compute_prediction(before_table, target)\n",
    "                    tree_paths.append(path)\n",
    "            #end for loop\n",
    "\n",
    "            current_paths = new_paths\n",
    "            if current_paths != []:\n",
    "                k -= 1\n",
    "            else:\n",
    "                break  # nothing left to extend so have copied all paths to tree_paths\n",
    "        #end while loop\n",
    "\n",
    "        #Generate predictions for all paths that have None\n",
    "        for path in current_paths:\n",
    "            conjunct = path['conjunction']\n",
    "            before_table = generate_table(train, conjunct)\n",
    "            path['prediction'] = compute_prediction(before_table, target)\n",
    "            tree_paths.append(path)\n",
    "        return (tree_paths, oob_list)\n",
    "    \n",
    "    #let's build the forest\n",
    "    forest = []\n",
    "    for i in range(tree_n):\n",
    "        (paths, oob) = iterative_build(k)\n",
    "        forest.append({'paths': paths, 'weight': None, 'oob': oob})\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Ok, let's build a forest with 5 trees (the default).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={})\n",
    "len(forest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now get predictions by voting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_table['forest_2'] = titanic_table.apply(lambda row: vote_taker(row, forest2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Follow normal process now. Produce column of types.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_table['forest_2_type'] = titanic_table.apply(lambda row: predictor_case(row, pred='forest_2', target='Survived'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Produce type counts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_negative     457\n",
       "true_positive     217\n",
       "false_negative    125\n",
       "false_positive     92\n",
       "Name: forest_2_type, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2_types = titanic_table['forest_2_type'].value_counts()  # returns a series\n",
    "forest2_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Print measures.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7564534231200898, 0.6666666666666666, 0.4669255104975554)\n"
     ]
    }
   ],
   "source": [
    "print((accuracy(forest2_types), f1(forest2_types), informedness(forest2_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Try 2 more\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "One with 11 trees with depth of 2, and one with 11 trees and depth of 1 (i.e., 11 stumps).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest3 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={'total-trees':11})\n",
    "len(forest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.77665544332211, 0.716927453769559, 0.5382993001629757)\n"
     ]
    }
   ],
   "source": [
    "titanic_table['forest_3'] = titanic_table.apply(lambda row: vote_taker(row, forest3), axis=1)\n",
    "titanic_table['forest_3_type'] = titanic_table.apply(lambda row: predictor_case(row, pred='forest_3', target='Survived'), axis=1)\n",
    "forest3_types = titanic_table['forest_3_type'].value_counts()  # returns a series\n",
    "print((accuracy(forest3_types), f1(forest3_types), informedness(forest3_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest4 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={'total-trees':11, 'max-depth':1})\n",
    "len(forest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7575757575757576, 0.5846153846153846, 0.39708561020036415)\n"
     ]
    }
   ],
   "source": [
    "titanic_table['forest_4'] = titanic_table.apply(lambda row: vote_taker(row, forest4), axis=1)\n",
    "titanic_table['forest_4_type'] = titanic_table.apply(lambda row: predictor_case(row, pred='forest_4', target='Survived'), axis=1)\n",
    "forest4_types = titanic_table['forest_4_type'].value_counts()  # returns a series\n",
    "print((accuracy(forest4_types), f1(forest4_types), informedness(forest4_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Should explore more\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "If we were ambitious, we could write yet another function that explored for us. Tried combinations of number of trees and depth and reported the best performing. I won't make you write this function but it should be in your grasp by this point. All you would be doing is repeating steps above but now in nested loops that produced various combinations to try.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Ouf Of Bag errors\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We could now use K-Folding to do a better evaluation of our forests. But I want to consider another approach called *Out of Bag error* (jargon alert). You will now see where that `oob` value on a tree comes in handy. As reminder, for each tree we generated a training sample. But that sample always leaves some rows out because of replacement. We captured these \"left out\" rows in the `oob` entry. We actually captured the row indices in the larger Titanic table.\n",
    "<p>\n",
    "Here's what I would like to do. I would like to evaluate a forest on the out of bag rows. It kind of makes sense, right? A tree was trained on some set of rows that excluded the rows in oob. So the oob rows are a bit like the test data from K-Folding. We use the oob rows for testing.\n",
    "\n",
    "One way to look at it is I create a new testing table that is the union of the oob list on each tree. I then use this testing table to get predictions by forest vote taking. Here is the twist: a tree gets to vote on a row only if the row is in its oob list.\n",
    "<p>\n",
    "I am going to give you the chance to decide how to implement oob testing as part of your homework assignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "<h1>Write it out</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "Save the table so can use it in next module.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "week = 6  # change this each week\n",
    "\n",
    "home_path =  os.path.expanduser('~')\n",
    "\n",
    "file_path = '/Dropbox/cis399_ds1_f17/notebook_history/'\n",
    "\n",
    "file_name = 'titanic_wrangled_w'+str(week)+'.csv'\n",
    "\n",
    "titanic_table.to_csv(home_path + file_path + file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>\n",
    "Next up\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We will continue to look at forests. But study an alternative way to consturcting the trees that is kind of cool.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
